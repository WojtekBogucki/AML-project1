---
title: "Raport 1"
author: "Wojciech Bogucki, Michał Pastuszka"
date: "28 03 2021"
geometry: margin=1cm
output: 
  pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.pos = "!H")
library(kableExtra)
library(ggpubr)
library(ggplot2)
library(MASS)
library(class)
library(microbenchmark)
library(dplyr)
source("src/measure.R")
source("src/gradient_descent.R")
source("src/iwls.R")
source("src/util.R")
source("src/optim_logreg.R")
load("data/jain_train.Rda")
load("data/jain_test.Rda")
load("data/spambase_train.Rda")
load("data/spambase_test.Rda")
load("data/mammography_train.Rda")
load("data/mammography_test.Rda")
load("data/skin_seg_train.Rda")
load("data/skin_seg_test.Rda")
load("data/occupancy_train.Rda")
load("data/occupancy_test.Rda")
set.seed(123)


```
# Datasets
```{r data_stats, fig.width=8, cache=TRUE}
datasets_names <- c("Jain", "Spambase", "Mammography","Skin segmentation", "Occupancy")
nrows<- c(dim(jain_train)[1], dim(spambase_train)[1], dim(mammography_train)[1], dim(skin_seg_train)[1], dim(occupancy_train)[1])
ncols <- c(dim(jain_train)[2], dim(spambase_train)[2], dim(mammography_train)[2], dim(skin_seg_train)[2], dim(occupancy_train)[2]) - 1
class_ratio <- c(mean(jain_train$V3), mean(spambase_train$TARGET), mean(mammography_train$class), mean(skin_seg_train$Class), mean(occupancy_train$Occupancy))
df <- data.frame(datasets_names, nrows, ncols, class_ratio)

kable(df, row.names = FALSE, digits = 2, caption = "Training dataset's statistics", col.names = c("Dataset name","Number of obeservations", "Number of predictors", "Target class ratio" )) %>% kable_styling(full_width = FALSE, latex_options = "hold_position")

```
Datasets used in this project were: `Jain` [(link)](http://cs.joensuu.fi/sipu/datasets/), `Spambase` [(link)](https://archive.ics.uci.edu/ml/datasets/Spambase), `Mammography` [(link)](https://www.openml.org/d/310), `Skin segmentation` [(link)](https://www.openml.org/d/1502) and `Occupancy` [(link)](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+).
All columns were standardized. Datasets were split on training set and test set according to ratio $80:20$. Values of tagret column in each dataset were replaced with $0$ and $1$ when neccessary. Statisctics of each training set are presented in Table 1.

# Methods

Three main optimization algorithms for logistic regression were tested: **Gradient Descent** (GD), **Stochastic Gradient Descent** (SGD) and **Iterated Weighted Least Squares** (IWLS). Two additional algorithms from function `optim()` also were tested: **Conjugate Gradient** (CG) with Polak-Ribiere update and **Broyden–Fletcher–Goldfarb–Shanno** (BFGS).

# Experiments
## Convergence analysis
The aim of this analysis was to compare convergence of different algorithms. Stopping rules were: change of value of loss function lower than $10^{-4}$ after iteration and maximal limit of iterations -- $100$.

### Learning rate
Firstly, impact of learning rate in gradient descent algorithms was tested on dataset `spambase`. On Figure 1 we can see that SGD is instable for big learning rate ($0.05$). The fastest and the best learning rate equals $0.01$. On the other hand, for GD the higher value of learning rate the faster algorithm converges.


```{r lr_SGD, cache=TRUE}
X <- as.matrix(spambase_train[,-ncol(spambase_train)])
Y <- as.matrix(spambase_train[,ncol(spambase_train)])


models <- list()
max_iter <- 100
epsilon <- 1e-4
lr <- c(0.05, 0.01, 0.005, 0.001)
for (i in 1:4){
  models[[i]] <- sgd(X, Y, epsilon , max_iter, lr[i])
}


g1 <- compare_models(models, labels = paste("lr =", lr), title = "Stochastic Gradient Descent")
g1 <- g1 + labs(color="Params") + theme(legend.position="bottom")
```

```{r lr_GD, fig.height=3, fig.width=10, fig.cap="Values of loss during training with different learning rates", fig.pos="h", cache=TRUE, out.extra=''}
models <- list()
max_iter <- 1000
epsilon <- 1e-4
lr <- c(1, 0.75, 0.5, 0.3, 0.2, 0.1, 0.05)
n <- length(lr)
for (i in 1:n){
  models[[i]] <- gradient_descent(X, Y, epsilon, max_iter, lr[i])

}
g2 <- compare_models(models, labels = paste("lr =", lr), title = "Gradient Descent")
g2 <- g2 + labs(color="Params")  + theme(legend.position="bottom")
ggarrange(g1 , g2, nrow=1)
```



### Value of log-likelihood function
As it is shown on Figure 2 -- convergence of dfferent algorithms for different dataset looks similar. Two slowest methods are GD and CG. In plot of Conjugate Gradient method's loss we can see that it periodically raises and the line is not smooth. In most cases the fastest and the best method is IWLS. For dataset `Mammography` SGD was comparable with IWLS. BFGS method sometimes converges faster and sometimes needs more iterations but it always yields final loss value similar to IWLS and SGD (Table 2).
```{r prep_models_jain, warning=FALSE, cache=TRUE}
X <- as.matrix(jain_train[,-ncol(jain_train)])
Y <- as.matrix(jain_train[,ncol(jain_train)])

max_iter <- 100
epsilon <- 1e-4


model <- gradient_descent(X, Y, epsilon, max_iter, 0.75)
model2 <- sgd(X, Y, epsilon , max_iter, 0.01)
model3 <- iwls(X, Y, epsilon, max_iter)
model4 <- optim_logreg(X, Y, method = "CG", epsilon, max_iter)
model5 <- optim_logreg(X, Y, method = "BFGS", epsilon, max_iter)
labels <- c("GD", "SGD", "IWLS", "CG", "BFGS")


df <- data.frame(algorithm=labels, jain=c(model$costs[model$iters+1],model2$costs[model2$iters+1], model3$costs[model3$iters+1], model4$costs[model4$iters+1], model5$costs[model5$iters+1]))


g1 <- compare_models(list(model,model2, model3, model4, model5), labels = labels , title = "Dataset Jain")
g1 <- g1 + theme(legend.position="bottom")

```

```{r jain_time, cache=TRUE}
micro1 <- microbenchmark(GD = gradient_descent(X, Y, epsilon, max_iter, 0.75),
                        SGD = sgd(X, Y, epsilon , max_iter, 0.01),
                        IWLS = iwls(X, Y, epsilon, max_iter),
                        CG = optim_logreg(X, Y, method = "CG", epsilon, max_iter),
                        BFGS = optim_logreg(X, Y, method = "BFGS", epsilon, max_iter),
               times = 10, unit='ms')
time_stats1 <- cbind(summary(micro1)[, c(1,4)], iters=sapply(list(model, model2, model3, model4, model5), function(m) m$iters))
time_stats1 <- time_stats1 %>% mutate(ms_per_iter=mean/iters) %>% rename(mean_ms = mean)
```


```{r prep_models_spam, warning=FALSE, cache=TRUE}
X <- as.matrix(spambase_train[,-ncol(spambase_train)])
Y <- as.matrix(spambase_train[,ncol(spambase_train)])


max_iter <- 100
epsilon <- 1e-4

model <- gradient_descent(X, Y, epsilon, max_iter, 0.75)
model2 <- sgd(X, Y, epsilon , max_iter, 0.01)
model3 <- iwls(X, Y, epsilon, max_iter)
model4 <- optim_logreg(X, Y, method = "CG", epsilon, max_iter)
model5 <- optim_logreg(X, Y, method = "BFGS", epsilon, max_iter)

df <- cbind(df, data.frame(spambase=c(model$costs[model$iters+1],model2$costs[model2$iters+1], model3$costs[model3$iters+1], model4$costs[model4$iters+1], model5$costs[model5$iters+1])))


g2 <- compare_models(list(model,model2, model3, model4, model5), labels = c("GD", "SGD", "IWLS", "CG", "BFGS"), title = "Dataset Spambase")
g2 <- g2 + theme(legend.position="bottom")
```

```{r spam_time, cache=TRUE}
micro2 <- microbenchmark(gd = gradient_descent(X, Y, epsilon, max_iter, 0.75),
                         sgd = sgd(X, Y, epsilon , max_iter, 0.01),
                         iwls = iwls(X, Y, epsilon, max_iter),
                         cg = optim_logreg(X, Y, method = "CG", epsilon, max_iter),
                         bfgs = optim_logreg(X, Y, method = "BFGS", epsilon, max_iter),
                         times = 10, unit='s')
time_stats2 <- cbind(summary(micro2)[, c(1,4)], iters=sapply(list(model, model2, model3, model4, model5), function(m) m$iters))
time_stats2 <- time_stats2 %>% mutate(ms_per_iter=1000*mean/iters) %>% rename(mean_s = mean)
```




```{r prep_models_mamm, warning=FALSE, cache=TRUE}
X <- as.matrix(mammography_train[,-ncol(mammography_train)])
Y <- as.matrix(mammography_train[,ncol(mammography_train)])

max_iter <- 100
epsilon <- 1e-4
lr <- 0.01

model <- gradient_descent(X, Y, epsilon, max_iter, 0.75)
model2 <- sgd(X, Y, epsilon , max_iter, lr)
model3 <- iwls(X, Y, epsilon, max_iter)
model4 <- optim_logreg(X, Y, method = "CG", epsilon, max_iter)
model5 <- optim_logreg(X, Y, method = "BFGS", epsilon, max_iter)

df <- cbind(df, data.frame(mammography=c(model$costs[model$iters+1],model2$costs[model2$iters+1], model3$costs[model3$iters+1], model4$costs[model4$iters+1], model5$costs[model5$iters+1])))


g3 <- compare_models(list(model,model2, model3, model4, model5), labels = c("GD", "SGD", "IWLS", "CG", "BFGS"), title = "Dataset Mammography")
g3 <- g3 + theme(legend.position="bottom")
```

```{r conv, fig.height=2.5, fig.width=9,  fig.cap="Values of loss during training for different algorithms", fig.pos="h", out.extra=''}
ggarrange(g1 , g2, g3, nrow=1, common.legend = TRUE, legend = "bottom")
```

```{r prep_models_skin, warning=FALSE, cache=TRUE}
X <- as.matrix(skin_seg_train[,-ncol(skin_seg_train)])
Y <- as.matrix(skin_seg_train[,ncol(skin_seg_train)])

max_iter <- 100
epsilon <- 1e-4
lr <- 0.01

model <- gradient_descent(X, Y, epsilon, max_iter, 0.75)
model2 <- sgd(X, Y, epsilon , max_iter, lr)
model3 <- iwls(X, Y, epsilon, max_iter)
model4 <- optim_logreg(X, Y, method = "CG", epsilon, max_iter)
model5 <- optim_logreg(X, Y, method = "BFGS", epsilon, max_iter)

df <- cbind(df, data.frame(skin_seg=c(model$costs[model$iters+1],model2$costs[model2$iters+1], model3$costs[model3$iters+1], model4$costs[model4$iters+1], model5$costs[model5$iters+1])))


```


```{r prep_models_occ, warning=FALSE, cache=TRUE}
X <- as.matrix(occupancy_train[,-ncol(occupancy_train)])
Y <- as.matrix(occupancy_train[,ncol(occupancy_train)])

max_iter <- 100
epsilon <- 1e-4
lr <- 0.01

model <- gradient_descent(X, Y, epsilon, max_iter, 0.75)
model2 <- sgd(X, Y, epsilon , max_iter, lr)
model3 <- iwls(X, Y, epsilon, max_iter)
model4 <- optim_logreg(X, Y, method = "CG", epsilon, max_iter)
model5 <- optim_logreg(X, Y, method = "BFGS", epsilon, max_iter)

df <- cbind(df, data.frame(occupancy=c(model$costs[model$iters+1],model2$costs[model2$iters+1], model3$costs[model3$iters+1], model4$costs[model4$iters+1], model5$costs[model5$iters+1])))
```


```{r table}
knitr::kable(df, digits = 3, row.names = FALSE, caption = "Final loss for different algorithms on various datasets", col.names = c("Algorithm", "Jain", "Spambase", "Mammography","Skin segmentation", "Occupancy")) %>% kable_styling(full_width = FALSE, latex_options = "hold_position")
```

### Time of exectuion
Another important thing that was wested was time of executon of particular algorithm as well as time of execution per one iteration. Average execution time was measured for 10 executions of function.

In Table 3 there are shown results measured on datasets *Jain* and *spambase*. In both cases IWLS algorithm has the longest time of executing one iteration but because of its fast convergence it has shorter overall execution time than SGD. Simple Gradient Descent is the fastest in execution but it usually has also bigger final loss value than SGD, IWLS or BFGS (Table 2). 

```{r time_comp}
columns <- c("Algorithm", "Average execution time (ms)", "Number of iterations", "Average execution time of 1 iteration (ms)","Average execution time (s)", "Number of iterations", "Average execution time of 1 iteration (ms)")

kable(cbind(time_stats1, time_stats2[,-1]), row.names = FALSE, digits = 2, caption = "Comparison of execution time for different algorithms", col.names = columns) %>% kable_styling(full_width = FALSE, latex_options = "hold_position") %>% add_header_above(c(" ", "Jain" = 3, "Spambase" = 3)) %>% column_spec(2:7, width="1.5cm")
```


## Model performance analysis
The aim of this experiment was to compare the performance of logistic regression with other popular models. We tested all optimization methods mentioned earlier together with $k$--nearest neighbors using $k={1,2,3}$ as well as linear and quadratic discriminant analysis. Following plots show accuracy, $F1$ score and $R^2$ measure achieved by this models.

# Comparison of opimization methods.

As our results show there is no significant difference in quality of fit achieved by used methods, with the exception of gradient descent. This method constantly underperformed in all tests, which is in line with previous results that show the slowest convergence rate for this method.

# Comparison with other models.

The `knn` models achieved best scores on sets `Jain` and `Occupancy`. The difference is especially visible in the first case. The dataset `Jain` consists of two classes that do not overlap, but cannot be separated easily by a linear or quadratic plane. This case shows where this type of model performs best. It is able to create a very good fit where the separating plane is highly irregular. It has however serious problems, when the classes highly overlap. In cases of the sets `Mammography` and `Skin segmentation` we were unable to  build a `knn` model at all, as it returned a `too many ties` error.

In case of `lda` and `qda` at first glance they appear to perform generally worse that logistic regression. A notable exception is the dataset `Skin segmentation`, where `qda` achieved near perfect fit and significantly outperformed competition. This suggests that this set, unlike the rest, matches well the assumptions this model is based on. Discriminant analysis models seem to perform particularly poorly on the set `Mammography` where they both present a negative $R^2$ score, suggesting a fit worse than a null model. This dataset however contains highly unbalanced classes. Looking at the recall statistic we see that this models were able to detect significantly more positive cases than logistic regression. It came at the cost of worse precision, but in the case of medical applications models with high recall are usually preferred. We have to still keep in mind, that we could possibly achieve similar or better results using the logistic model by lowering the classification threshold. Therefore, comparing those two models would require more detailed analysis. This case shows that looking only at measures such as `accuracy`, `R^2`  and `F1` may be misleading in the case of unbalanced classes.

Our experiments show no clear winner among the tested methods. Logistic regression appears to be the most well rounded of all, not performing the worst in any of the tests, but picking a correct model for the situation is the best option.

```{r get_measures, echo=FALSE}
get_measures <- function(X, Y, X_test, Y_test, do_knn=TRUE, add_prs=FALSE){
  gd.model <- gradient_descent(X, Y, 1e-4, 1000, 0.03)
  gd.pred <- predict(gd.model, X_test)
  sgd.model <- sgd(X, Y, 1e-4 , 1000, 0.01, verbose=FALSE)
  sgd.pred <- predict(sgd.model, X_test)
  iwls.model <- iwls(X, Y, 1e-4 , 1000)
  iwls.pred <- predict(iwls.model, X_test)
  bfgs.model <- optim_logreg(X, Y, "BFGS", 1e-4, 1000)
  bfgs.pred <- predict(bfgs.model, X_test)
  cg.model <- optim_logreg(X, Y, "CG", 1e-4)
  cg.pred <- predict(cg.model, X_test)
  
  lda.model <- lda(X, Y)
  lda.pred <- predict(lda.model, X_test)$class
  lda.pred <- as.numeric(levels(lda.pred))[lda.pred]
  qda.model <- qda(x=X, grouping = Y)
  qda.pred <- predict(qda.model, as.data.frame(X_test))$class
  qda.pred <- as.numeric(levels(qda.pred))[qda.pred]
  
  if(do_knn){
    knn1.pred <- knn(train = X, test = X_test, cl = Y, k = 1)
    knn1.pred <- as.numeric(levels(knn1.pred))[knn1.pred]
    knn3.pred <- knn(train = X, test = X_test, cl = Y, k = 3)
    knn3.pred <- as.numeric(levels(knn3.pred))[knn3.pred]
    knn5.pred <- knn(train = X, test = X_test, cl = Y, k = 5)
    knn5.pred <- as.numeric(levels(knn5.pred))[knn5.pred]
  }else{
    knn1.pred <- rep(NA, length.out=length(iwls.pred))
    knn3.pred <- rep(NA, length.out=length(iwls.pred))
    knn5.pred <- rep(NA, length.out=length(iwls.pred))
  }
  
  
  predictions <- list(gd = gd.pred, sgd = sgd.pred, iwls = iwls.pred, 
                      bfgs = bfgs.pred, cg = cg.pred, lda = lda.pred, 
                      qda = qda.pred, knn1 = knn1.pred, knn3 = knn3.pred, 
                      knn5 = knn5.pred)
  
  
  measures <- data.frame(t(sapply(predictions, 
                                  function(x) unlist(measure(Y_test, x)))))
  if(!do_knn){
    measures['knn1',] <- rep(0, length.out = ncol(measures))
    measures['knn3',] <- rep(0, length.out = ncol(measures))
    measures['knn5',] <- rep(0, length.out = ncol(measures))
  }
  
  measures['model'] <- rownames(measures)
  measures['model type'] <- c(rep('logistic regression', 5), 
                              rep('discriminatory analysis', 2),
                              rep('k nearest neighbors', 3))
  measures_melt <- reshape2::melt(measures, id.vars = c('model', 'model type'))
  desired_measures <- c('accuracy', 'f1_score', 'r2_score')
  if(add_prs){
    desired_measures <- c(desired_measures, 'precision', 'recall', 'specificity')
  }
  measures_melt[measures_melt$variable %in% desired_measures,]
}

```

```{r jain, echo=FALSE, fig.width=10, fig.height=2.5, cache=TRUE}
X <- as.matrix(jain_train[,-ncol(jain_train)])
Y <- as.matrix(jain_train[,ncol(jain_train)])

X_test <- as.matrix(jain_test[,-ncol(jain_test)])
Y_test <- as.matrix(jain_test[,ncol(jain_test)])

measures <- get_measures(X, Y, X_test, Y_test)

ggplot(measures, 
       aes(x = reorder(model, -value), y = value, fill = `model type`)) + 
  geom_bar(stat='identity') + scale_fill_brewer(palette=1, type='qual') + 
  facet_wrap(vars(variable), scales='free', ncol = 3) + 
  labs(title='Jain', x='Model') +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 35, vjust = 1, hjust=1))
```

```{r spambase, echo=FALSE, fig.width=10, fig.height=2.5, cache=TRUE}
X <- as.matrix(spambase_train[,-ncol(spambase_train)])
Y <- as.matrix(spambase_train[,ncol(spambase_train)])

X_test <- as.matrix(spambase_test[,-ncol(spambase_test)])
Y_test <- as.matrix(spambase_test[,ncol(spambase_test)])

measures <- get_measures(X, Y, X_test, Y_test)

ggplot(measures, 
       aes(x = reorder(model, -value), y = value, fill = `model type`)) + 
  geom_bar(stat='identity') + scale_fill_brewer(palette=1, type='qual') + 
  facet_wrap(vars(variable), scales='free', ncol = 3) + 
  labs(title='Spambase', x='Model') +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 35, vjust = 1, hjust=1))
```

```{r mammography, echo=FALSE, fig.width=10, fig.height=4, cache=TRUE}
X <- as.matrix(mammography_train[,-ncol(mammography_train)])
Y <- as.matrix(mammography_train[,ncol(mammography_train)])

X_test <- as.matrix(mammography_test[,-ncol(mammography_test)])
Y_test <- as.matrix(mammography_test[,ncol(mammography_test)])

measures <- get_measures(X, Y, X_test, Y_test, FALSE, TRUE)

ggplot(measures, 
       aes(x = reorder(model, -value), y = value, fill = `model type`)) + 
  geom_bar(stat='identity') + scale_fill_brewer(palette=1, type='qual') + 
  facet_wrap(vars(variable), scales='free', ncol = 3) + 
  labs(title='Mammography', x='Model') +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 35, vjust = 1, hjust=1))
```

```{r skinseg, echo=FALSE, fig.width=10, fig.height=2.5, cache=TRUE}
X <- as.matrix(skin_seg_train[,-ncol(skin_seg_train)])
Y <- as.matrix(skin_seg_train[,ncol(skin_seg_train)])

X_test <- as.matrix(skin_seg_test[,-ncol(skin_seg_test)])
Y_test <- as.matrix(skin_seg_test[,ncol(skin_seg_test)])


measures <- get_measures(X, Y, X_test, Y_test, do_knn = FALSE)

ggplot(measures, 
       aes(x = reorder(model, -value), y = value, fill = `model type`)) + 
  geom_bar(stat='identity') + scale_fill_brewer(palette=1, type='qual') + 
  facet_wrap(vars(variable), scales='free', ncol = 3) + 
  labs(title='Skin segmentation', x='Model') +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 35, vjust = 1, hjust=1))
```

```{r occupancy, echo=FALSE, fig.width=10, fig.height=2.5, cache=TRUE}
X <- as.matrix(occupancy_train[,-ncol(occupancy_train)])
Y <- as.matrix(occupancy_train[,ncol(occupancy_train)])

X_test <- as.matrix(occupancy_test[,-ncol(occupancy_test)])
Y_test <- as.matrix(occupancy_test[,ncol(occupancy_test)])

measures <- get_measures(X, Y, X_test, Y_test)

ggplot(measures, 
       aes(x = reorder(model, -value), y = value, fill = `model type`)) + 
  geom_bar(stat='identity') + scale_fill_brewer(palette=1, type='qual') + 
  facet_wrap(vars(variable), scales='free', ncol = 3) + 
  labs(title='Occupancy', x='Model') +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 35, vjust = 1, hjust=1))
```
